{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc8b4d3b-6e38-44a0-89fd-d47175ed725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "211ab46a-ac8c-4878-b97a-e43e3ed8c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: [  0  10  20  30  40  50  60  70  80  90 100]\n",
      "Actions: ['FILL', 'STOP']\n"
     ]
    }
   ],
   "source": [
    "#Define State and Actions \n",
    "states = np.arange(0, 101, 10)   # 0, 10,20,30,40..........100\n",
    "actions = ['FILL', 'STOP']       #Fill or Stop\n",
    "print('States:', states)\n",
    "print('Actions:', actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31b49153-ade1-4ae7-8939-3401d1c1acbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table shape: (11, 2)\n"
     ]
    }
   ],
   "source": [
    "#create Q table and set alpha, gamma, epsilon, episodes\n",
    "#Q Table: [s,a]\n",
    "Q = np.zeros((len(states), len(actions)))\n",
    "\n",
    "alpha = 0.1     # Learning rate\n",
    "gamma = 0.9     # Discount factor\n",
    "epsilon = 0.2   # Exploration rate\n",
    "episodes = 300  # Training runs\n",
    "\n",
    "print('Q-table shape:', Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bea2a21c-f7df-4673-a7a5-f3d0fda59d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Example (level=60, FILL): 10\n"
     ]
    }
   ],
   "source": [
    "#Write Reward , Penality function\n",
    "def get_reward(level, action):\n",
    "    if 40 <= level <= 70:\n",
    "        reward = 10  # ideal range\n",
    "    else:\n",
    "        reward = -10  # too low/high\n",
    "    if action == 'FILL' and level >= 90:\n",
    "        reward -= 10  # overflow risk\n",
    "    if action == 'STOP' and level <= 10:\n",
    "        reward -= 10  # empty risk\n",
    "    return reward\n",
    "\n",
    "print('Reward Example (level=60, FILL):', get_reward(60, 'FILL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "721f90d5-139e-4361-97bd-c4fde94dfdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Level Example: 60\n"
     ]
    }
   ],
   "source": [
    "def next_level(level, action):\n",
    "    if action == 'FILL':\n",
    "        level += random.choice([5, 10, 15])\n",
    "    else:\n",
    "        level -= random.choice([5, 10, 15])\n",
    "    return int(np.clip(level, 0, 100))\n",
    "\n",
    "print('Next Level Example:', next_level(50, 'FILL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "629bc550-db3d-48f3-bfe5-9338fddb71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "for ep in range(episodes):\n",
    "    level = random.choice(states)\n",
    "    for _ in range(15):  # steps per episode\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(actions)\n",
    "        else:\n",
    "            action = actions[np.argmax(Q[level // 10])]\n",
    "\n",
    "        next_state = next_level(level, action)\n",
    "        reward = get_reward(next_state, action)\n",
    "\n",
    "        a = actions.index(action)\n",
    "        best_next = np.max(Q[next_state // 10])\n",
    "        Q[level // 10, a] += alpha * (reward + gamma * best_next - Q[level // 10, a])\n",
    "print('Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69de6c43-e814-4b9a-890f-73e7387d38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter starting water level (0–100):  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting with level: 70%\n",
      "Simulating for 10 steps:\n",
      "\n",
      "Step 1: Level=70% → Action=STOP\n",
      "Step 2: Level=60% → Action=STOP\n",
      "Step 3: Level=55% → Action=FILL\n",
      "Step 4: Level=65% → Action=STOP\n",
      "Step 5: Level=50% → Action=FILL\n",
      "Step 6: Level=55% → Action=FILL\n",
      "Step 7: Level=60% → Action=STOP\n",
      "Step 8: Level=45% → Action=FILL\n",
      "Step 9: Level=60% → Action=STOP\n",
      "Step 10: Level=45% → Action=FILL\n",
      "\\Simulation complete. Water tank control finished.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    level = int(input('Enter starting water level (0–100): '))\n",
    "    if level < 0 or level > 100:\n",
    "        raise ValueError('Water level out of range!')\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    level = 50\n",
    "    print('Defaut level set to 50%.')\n",
    "\n",
    "print(f'\\nStarting with level: {level}%')\n",
    "print('Simulating for 10 steps:\\n')\n",
    "\n",
    "for step in range(10):\n",
    "    action = actions[np.argmax(Q[level // 10])]\n",
    "    print(f'Step {step+1}: Level={level}% → Action={action}')\n",
    "    level = next_level(level, action)\n",
    "\n",
    "print('\\Simulation complete. Water tank control finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43417511-567e-43a8-8e91-27f165b95433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter starting water level (0–100):  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting with level: 70%\n",
      "Simulating for 10 steps:\n",
      "\n",
      "Step 1: Level=70% → Action=STOP\n",
      "Step 2: Level=60% → Action=STOP\n",
      "Step 3: Level=45% → Action=FILL\n",
      "Step 4: Level=50% → Action=FILL\n",
      "Step 5: Level=55% → Action=FILL\n",
      "Step 6: Level=60% → Action=STOP\n",
      "Step 7: Level=55% → Action=FILL\n",
      "Step 8: Level=65% → Action=STOP\n",
      "Step 9: Level=50% → Action=FILL\n",
      "Step 10: Level=55% → Action=FILL\n",
      "\\Simulation complete. Water tank control finished.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    level = int(input('Enter starting water level (0–100): '))\n",
    "    if level < 0 or level > 100:\n",
    "        raise ValueError('Water level out of range!')\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    level = 50\n",
    "    print('Defaut level set to 50%.')\n",
    "\n",
    "print(f'\\nStarting with level: {level}%')\n",
    "print('Simulating for 10 steps:\\n')\n",
    "\n",
    "for step in range(10):\n",
    "    action = actions[np.argmax(Q[level // 10])]\n",
    "    print(f'Step {step+1}: Level={level}% → Action={action}')\n",
    "    level = next_level(level, action)\n",
    "\n",
    "print('\\Simulation complete. Water tank control finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8bd450-2e17-4c99-b310-3ad7391a719c",
   "metadata": {},
   "source": [
    "# Exercise: Smart Traffic Light Controller Using Q-Learning\n",
    "## Objective: In this exercise, you'll design a Smart Traffic Light System that learns when to switch lights (Green/Red) based on real-time traffic conditions using Q-Learning. Your AI agent will balance reducing waiting time for vehicles, saving energy, and maintaining safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30362a9b-6a1c-4ee0-b14c-0462657d8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "26b34035-51c0-4538-bf0c-c170ca1a1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic States:\n",
      "  0 = Empty road\n",
      "  1 = Light traffic\n",
      "  2 = Moderate traffic\n",
      "  3 = Heavy traffic\n",
      "  4 = Very heavy traffic\n",
      "\n",
      "Actions:\n",
      "  GREEN = Keep the light green (GO)\n",
      "  RED = Turn the light red (STOP)\n"
     ]
    }
   ],
   "source": [
    "states = [0, 1, 2, 3, 4]\n",
    "actions = ['GREEN', 'RED']\n",
    "print(\"Traffic States:\")\n",
    "for s in states:\n",
    "    if s == 0:\n",
    "        label = \"Empty road\"\n",
    "    elif s == 1:\n",
    "        label = \"Light traffic\"\n",
    "    elif s == 2:\n",
    "        label = \"Moderate traffic\"\n",
    "    elif s == 3:\n",
    "        label = \"Heavy traffic\"\n",
    "    elif s == 4:\n",
    "        label = \"Very heavy traffic\"\n",
    "    print(f\"  {s} = {label}\")\n",
    "print(\"\\nActions:\")\n",
    "for a in actions:\n",
    "    if a == 'GREEN':\n",
    "        meaning = \"Keep the light green (GO)\"\n",
    "    else:\n",
    "        meaning = \"Turn the light red (STOP)\"\n",
    "    print(f\"  {a} = {meaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f87acc0-e482-408f-9ac9-543c0fc7957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table shape: (5, 2)\n",
      "Initial Q-table:\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Q = np.zeros((len(states), len(actions)))\n",
    "alpha = 0.1     # Learning rate\n",
    "gamma = 0.9     # Discount factor\n",
    "epsilon = 0.2   # Exploration rate\n",
    "episodes = 300  # Number of training episodes\n",
    "\n",
    "print('Q-table shape:', Q.shape)\n",
    "print('Initial Q-table:\\n', Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93be1209-4ece-49f2-9e64-a1d7398a361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(traffic, action):\n",
    "    if traffic in [3, 4]:  # Heavy or very heavy\n",
    "        if action == 'GREEN':\n",
    "            return +10   # Good: clear congestion\n",
    "        else:\n",
    "            return -10   # Bad: jams  \n",
    "    elif traffic == 0:\n",
    "        if action == 'RED':\n",
    "            return +5    # Good\n",
    "        else:\n",
    "            return -5    # Bad\n",
    "    elif traffic == 2:\n",
    "        return +1   \n",
    "    elif traffic == 1:\n",
    "        if action == 'RED':\n",
    "            return +2\n",
    "        else:\n",
    "            return 0     # Slightly less efficient\n",
    "\n",
    "    # Default (shouldn't happen)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03751349-2abf-4b8b-afd5-01f079c457a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic=3, Action=GREEN -> Reward=10\n",
      "Traffic=3, Action=RED -> Reward=-10\n",
      "Traffic=0, Action=RED -> Reward=5\n",
      "Traffic=0, Action=GREEN -> Reward=-5\n",
      "Traffic=2, Action=GREEN -> Reward=1\n",
      "Traffic=1, Action=RED -> Reward=2\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    (3, 'GREEN'),  # Heavy + Green\n",
    "    (3, 'RED'),    # Heavy + Red\n",
    "    (0, 'RED'),    # Empty + Red\n",
    "    (0, 'GREEN'),  # Empty + Green\n",
    "    (2, 'GREEN'),  # Moderate + Green\n",
    "    (1, 'RED')     # Light + Red\n",
    "]\n",
    "\n",
    "for traffic, action in test_cases:\n",
    "    print(f\"Traffic={traffic}, Action={action} -> Reward={get_reward(traffic, action)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8913b100-1c9e-4c66-b419-44307bf41918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial traffic: 1\n",
      "Step 1: Traffic level = 0\n",
      "Step 2: Traffic level = 0\n",
      "Step 3: Traffic level = 0\n",
      "Step 4: Traffic level = 0\n",
      "Step 5: Traffic level = 0\n",
      "Step 6: Traffic level = 1\n",
      "Step 7: Traffic level = 2\n",
      "Step 8: Traffic level = 3\n",
      "Step 9: Traffic level = 3\n",
      "Step 10: Traffic level = 3\n"
     ]
    }
   ],
   "source": [
    "def next_traffic(current):\n",
    "    change = random.choice([-1, 0, 1])\n",
    "    next_level = np.clip(current + change, 0, 4)\n",
    "\n",
    "    return next_level\n",
    "    traffic = 2  # Start with moderate traffic\n",
    "print(\"Initial traffic:\", traffic)\n",
    "\n",
    "for step in range(10):\n",
    "    traffic = next_traffic(traffic)\n",
    "    print(f\"Step {step+1}: Traffic level = {traffic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69ff7dcf-4c92-49f7-8a32-c072c4f8ac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed successfully!\n",
      "Final Q-table:\n",
      "[[35.28334674 46.4332045 ]\n",
      " [43.83576733 47.01886871]\n",
      " [56.61168645 47.93528592]\n",
      " [74.98489807 54.53235793]\n",
      " [83.31181435 59.42253221]]\n"
     ]
    }
   ],
   "source": [
    "for episode in range(episodes):\n",
    "    # Start from a random traffic level\n",
    "    state = np.random.randint(0, 5)\n",
    "    \n",
    "    for step in range(40):  # Steps per episode\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action_idx = np.random.randint(0, len(actions))  # Explore\n",
    "        else:\n",
    "            action_idx = np.argmax(Q[state])  # Exploit best action\n",
    "        \n",
    "        action = actions[action_idx]\n",
    "        \n",
    "        next_state = next_traffic(state)\n",
    "        reward = get_reward(state, action)\n",
    "        \n",
    "        Q[state, action_idx] = Q[state, action_idx] + alpha * (\n",
    "            reward + gamma * np.max(Q[next_state]) - Q[state, action_idx]\n",
    "        )\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "print(\"\\nTraining completed successfully!\")\n",
    "print(\"Final Q-table:\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78666def-a185-4444-bbd6-c6af72043285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid traffic index 70. Resetting to 0.\n",
      "Step 1: Traffic = Empty road  →  Action = RED\n",
      "Step 2: Traffic = Light traffic  →  Action = RED\n",
      "Step 3: Traffic = Light traffic  →  Action = RED\n",
      "Step 4: Traffic = Empty road  →  Action = RED\n",
      "Step 5: Traffic = Light traffic  →  Action = RED\n",
      "Step 6: Traffic = Light traffic  →  Action = RED\n",
      "Step 7: Traffic = Empty road  →  Action = RED\n",
      "Step 8: Traffic = Light traffic  →  Action = RED\n",
      "Step 9: Traffic = Empty road  →  Action = RED\n",
      "Step 10: Traffic = Light traffic  →  Action = RED\n"
     ]
    }
   ],
   "source": [
    "traffic = level\n",
    "for step in range(10):\n",
    "    # Ensure traffic index is valid\n",
    "    if traffic < 0 or traffic >= len(Q):\n",
    "        print(f\"Warning: Invalid traffic index {traffic}. Resetting to 0.\")\n",
    "        traffic = 0\n",
    "    \n",
    "    action_idx = np.argmax(Q[traffic])\n",
    "    action = actions[action_idx]\n",
    "    \n",
    "    print(f\"Step {step+1}: Traffic = {state_labels[traffic]}  →  Action = {action}\")\n",
    "    \n",
    "    # Simulate environment\n",
    "    traffic = next_traffic(traffic)\n",
    "    traffic = max(0, min(traffic, len(state_labels) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799d19c-e4fc-4407-bd5b-0fd93d3801e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
